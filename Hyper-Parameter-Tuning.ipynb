{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa4a415-6362-48bb-804b-5087244f07be",
   "metadata": {},
   "source": [
    "# Tuning a Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f961a-c133-42d2-862a-2c81d3a596b2",
   "metadata": {},
   "source": [
    "Custom built expanding window validation functions will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56a501ec-9254-400b-83fd-780c557fcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import your helper functions\n",
    "from timeseries_model_utils import (\n",
    "    expanding_window_splits,\n",
    "    run_expanding_cv,\n",
    "    expanding_window_grid_search\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edffff51-e61f-4a34-bd60-807a2c456b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Homicide</th>\n",
       "      <th>Assault</th>\n",
       "      <th>Sexual offences</th>\n",
       "      <th>Harm or endanger persons</th>\n",
       "      <th>Robbery, blackmail, and extortion</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Theft</th>\n",
       "      <th>Fraud and related offences</th>\n",
       "      <th>Drug offences</th>\n",
       "      <th>...</th>\n",
       "      <th>Public order, health, and safety offences</th>\n",
       "      <th>Traffic and vehicle offences</th>\n",
       "      <th>Offences against justice procedures and orders</th>\n",
       "      <th>Offences against government</th>\n",
       "      <th>Environmental offences</th>\n",
       "      <th>Miscellaneous offences</th>\n",
       "      <th>Total</th>\n",
       "      <th>Population</th>\n",
       "      <th>Crime_Index</th>\n",
       "      <th>Crime_Index_Lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>353</td>\n",
       "      <td>7208</td>\n",
       "      <td>1401</td>\n",
       "      <td>2176</td>\n",
       "      <td>426</td>\n",
       "      <td>11893</td>\n",
       "      <td>29103</td>\n",
       "      <td>19794</td>\n",
       "      <td>7839</td>\n",
       "      <td>...</td>\n",
       "      <td>28539</td>\n",
       "      <td>173948</td>\n",
       "      <td>27664</td>\n",
       "      <td>1376</td>\n",
       "      <td>3521</td>\n",
       "      <td>9651</td>\n",
       "      <td>331751</td>\n",
       "      <td>3112900</td>\n",
       "      <td>10.657297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>366</td>\n",
       "      <td>7933</td>\n",
       "      <td>1092</td>\n",
       "      <td>2299</td>\n",
       "      <td>494</td>\n",
       "      <td>12974</td>\n",
       "      <td>29654</td>\n",
       "      <td>25007</td>\n",
       "      <td>8340</td>\n",
       "      <td>...</td>\n",
       "      <td>22637</td>\n",
       "      <td>142990</td>\n",
       "      <td>17981</td>\n",
       "      <td>2027</td>\n",
       "      <td>3360</td>\n",
       "      <td>9836</td>\n",
       "      <td>294409</td>\n",
       "      <td>3124900</td>\n",
       "      <td>9.421389</td>\n",
       "      <td>10.657297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982</td>\n",
       "      <td>329</td>\n",
       "      <td>7760</td>\n",
       "      <td>1298</td>\n",
       "      <td>2231</td>\n",
       "      <td>504</td>\n",
       "      <td>14387</td>\n",
       "      <td>32682</td>\n",
       "      <td>26131</td>\n",
       "      <td>9518</td>\n",
       "      <td>...</td>\n",
       "      <td>18268</td>\n",
       "      <td>104739</td>\n",
       "      <td>13957</td>\n",
       "      <td>1203</td>\n",
       "      <td>4025</td>\n",
       "      <td>7878</td>\n",
       "      <td>252119</td>\n",
       "      <td>3156100</td>\n",
       "      <td>7.988308</td>\n",
       "      <td>9.421389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>407</td>\n",
       "      <td>8741</td>\n",
       "      <td>1449</td>\n",
       "      <td>2693</td>\n",
       "      <td>657</td>\n",
       "      <td>13851</td>\n",
       "      <td>32304</td>\n",
       "      <td>28481</td>\n",
       "      <td>10346</td>\n",
       "      <td>...</td>\n",
       "      <td>16067</td>\n",
       "      <td>105649</td>\n",
       "      <td>15332</td>\n",
       "      <td>736</td>\n",
       "      <td>2252</td>\n",
       "      <td>7774</td>\n",
       "      <td>254658</td>\n",
       "      <td>3199300</td>\n",
       "      <td>7.959804</td>\n",
       "      <td>7.988308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>406</td>\n",
       "      <td>9349</td>\n",
       "      <td>1682</td>\n",
       "      <td>2651</td>\n",
       "      <td>729</td>\n",
       "      <td>13905</td>\n",
       "      <td>33492</td>\n",
       "      <td>28069</td>\n",
       "      <td>12819</td>\n",
       "      <td>...</td>\n",
       "      <td>17456</td>\n",
       "      <td>116414</td>\n",
       "      <td>16389</td>\n",
       "      <td>1300</td>\n",
       "      <td>2235</td>\n",
       "      <td>8552</td>\n",
       "      <td>274022</td>\n",
       "      <td>3227100</td>\n",
       "      <td>8.491277</td>\n",
       "      <td>7.959804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Homicide  Assault  Sexual offences  Harm or endanger persons  \\\n",
       "0  1980       353     7208             1401                      2176   \n",
       "1  1981       366     7933             1092                      2299   \n",
       "2  1982       329     7760             1298                      2231   \n",
       "3  1983       407     8741             1449                      2693   \n",
       "4  1984       406     9349             1682                      2651   \n",
       "\n",
       "   Robbery, blackmail, and extortion  Burglary   Theft  \\\n",
       "0                                426      11893  29103   \n",
       "1                                494      12974  29654   \n",
       "2                                504      14387  32682   \n",
       "3                                657      13851  32304   \n",
       "4                                729      13905  33492   \n",
       "\n",
       "   Fraud and related offences  Drug offences  ...  \\\n",
       "0                       19794           7839  ...   \n",
       "1                       25007           8340  ...   \n",
       "2                       26131           9518  ...   \n",
       "3                       28481          10346  ...   \n",
       "4                       28069          12819  ...   \n",
       "\n",
       "   Public order, health, and safety offences  Traffic and vehicle offences  \\\n",
       "0                                      28539                        173948   \n",
       "1                                      22637                        142990   \n",
       "2                                      18268                        104739   \n",
       "3                                      16067                        105649   \n",
       "4                                      17456                        116414   \n",
       "\n",
       "   Offences against justice procedures and orders  \\\n",
       "0                                           27664   \n",
       "1                                           17981   \n",
       "2                                           13957   \n",
       "3                                           15332   \n",
       "4                                           16389   \n",
       "\n",
       "   Offences against government  Environmental offences  \\\n",
       "0                         1376                    3521   \n",
       "1                         2027                    3360   \n",
       "2                         1203                    4025   \n",
       "3                          736                    2252   \n",
       "4                         1300                    2235   \n",
       "\n",
       "   Miscellaneous offences   Total  Population  Crime_Index  Crime_Index_Lagged  \n",
       "0                    9651  331751     3112900    10.657297                 NaN  \n",
       "1                    9836  294409     3124900     9.421389           10.657297  \n",
       "2                    7878  252119     3156100     7.988308            9.421389  \n",
       "3                    7774  254658     3199300     7.959804            7.988308  \n",
       "4                    8552  274022     3227100     8.491277            7.959804  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"New_csv.csv\")   # replace with your file\n",
    "df = df.sort_values(\"Year\").reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5d41440-c8e6-4d3a-9137-c4257b2262c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45 entries, 0 to 44\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Year                                            45 non-null     int64  \n",
      " 1   Homicide                                        45 non-null     int64  \n",
      " 2   Assault                                         45 non-null     int64  \n",
      " 3   Sexual offences                                 45 non-null     int64  \n",
      " 4   Harm or endanger persons                        45 non-null     int64  \n",
      " 5   Robbery, blackmail, and extortion               45 non-null     int64  \n",
      " 6   Burglary                                        45 non-null     int64  \n",
      " 7   Theft                                           45 non-null     int64  \n",
      " 8   Fraud and related offences                      45 non-null     int64  \n",
      " 9   Drug offences                                   45 non-null     int64  \n",
      " 10  Weapons and explosives offences                 45 non-null     int64  \n",
      " 11  Property damage                                 45 non-null     int64  \n",
      " 12  Public order, health, and safety offences       45 non-null     int64  \n",
      " 13  Traffic and vehicle offences                    45 non-null     int64  \n",
      " 14  Offences against justice procedures and orders  45 non-null     int64  \n",
      " 15  Offences against government                     45 non-null     int64  \n",
      " 16  Environmental offences                          45 non-null     int64  \n",
      " 17  Miscellaneous offences                          45 non-null     int64  \n",
      " 18  Total                                           45 non-null     int64  \n",
      " 19  Population                                      45 non-null     int64  \n",
      " 20  Crime_Index                                     45 non-null     float64\n",
      " 21  Crime_Index_Lagged                              44 non-null     float64\n",
      "dtypes: float64(2), int64(20)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a75231b-03ab-446b-be66-3722f38bb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Crime_Index\"  \n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [ target_col]]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1c4f445-a1fe-4335-9582-e1ccb9214855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] Params {'n_estimators': 100, 'max_depth': 3} → Score = 0.4469\n",
      "[GridSearch] Params {'n_estimators': 100, 'max_depth': 5} → Score = 0.4104\n",
      "[GridSearch] Params {'n_estimators': 100, 'max_depth': None} → Score = 0.4130\n",
      "[GridSearch] Params {'n_estimators': 200, 'max_depth': 3} → Score = 0.4414\n",
      "[GridSearch] Params {'n_estimators': 200, 'max_depth': 5} → Score = 0.4144\n",
      "[GridSearch] Params {'n_estimators': 200, 'max_depth': None} → Score = 0.4045\n",
      "[GridSearch] Params {'n_estimators': 400, 'max_depth': 3} → Score = 0.4330\n",
      "[GridSearch] Params {'n_estimators': 400, 'max_depth': 5} → Score = 0.3991\n",
      "[GridSearch] Params {'n_estimators': 400, 'max_depth': None} → Score = 0.4057\n",
      "\n",
      "Best Parameters: {'n_estimators': np.float64(400.0), 'max_depth': np.float64(5.0)}\n",
      "Best Score: 0.3991015210797483\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.446937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.410434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.441433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.414386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.432994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.399102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth     score\n",
       "0           100        3.0  0.446937\n",
       "1           100        5.0  0.410434\n",
       "2           100        NaN  0.413027\n",
       "3           200        3.0  0.441433\n",
       "4           200        5.0  0.414386\n",
       "5           200        NaN  0.404482\n",
       "6           400        3.0  0.432994\n",
       "7           400        5.0  0.399102\n",
       "8           400        NaN  0.405693"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_depth\": [3, 5, None]\n",
    "}\n",
    "\n",
    "best_params, best_score, results_df = expanding_window_grid_search(\n",
    "    RandomForestRegressor,\n",
    "    param_grid,\n",
    "    X, y,\n",
    "    initial_train_size=10,\n",
    "    horizon=1,\n",
    "    step=1\n",
    ")\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1bd5fb0-420c-4eee-a36c-d8bdd345e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [0.001, 0.01, 0.1, 1, 10, 50, 100],\n",
    "    \"max_iter\": [1000, 5000, 10000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e66c6629-8158-45fc-b20d-f05283dcbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X.ffill().bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acbab412-6ca5-4690-afbd-2f2c07a66998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e-03, tolerance: 2.613e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.063e-03, tolerance: 2.614e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e-03, tolerance: 2.629e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e-03, tolerance: 2.635e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.759e-03, tolerance: 2.685e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.092e-03, tolerance: 2.845e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.414e-03, tolerance: 3.084e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.121e-03, tolerance: 3.706e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.029e-03, tolerance: 4.463e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.270e-03, tolerance: 5.207e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e-02, tolerance: 5.902e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e-02, tolerance: 6.658e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e-02, tolerance: 7.521e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e-02, tolerance: 8.479e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e-02, tolerance: 9.357e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e-02, tolerance: 1.077e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e-02, tolerance: 1.180e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e-02, tolerance: 1.255e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] Params {'alpha': 0.001, 'max_iter': 1000} → Score = 0.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.857e-03, tolerance: 3.706e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.946e-03, tolerance: 5.902e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] Params {'alpha': 0.001, 'max_iter': 5000} → Score = 0.1045\n",
      "[GridSearch] Params {'alpha': 0.001, 'max_iter': 10000} → Score = 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e-03, tolerance: 2.614e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.858e-03, tolerance: 2.629e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e-03, tolerance: 2.635e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.853e-03, tolerance: 2.685e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.088e-03, tolerance: 2.845e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.227e-03, tolerance: 3.084e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.673e-03, tolerance: 3.706e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.201e-03, tolerance: 4.463e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.359e-03, tolerance: 5.207e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e-02, tolerance: 5.902e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e-02, tolerance: 6.658e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e-02, tolerance: 7.521e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e-02, tolerance: 8.479e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e-02, tolerance: 9.357e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e-02, tolerance: 1.077e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e-02, tolerance: 1.180e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e-02, tolerance: 1.255e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] Params {'alpha': 0.01, 'max_iter': 1000} → Score = 0.1046\n",
      "[GridSearch] Params {'alpha': 0.01, 'max_iter': 5000} → Score = 0.1235\n",
      "[GridSearch] Params {'alpha': 0.01, 'max_iter': 10000} → Score = 0.1235\n",
      "[GridSearch] Params {'alpha': 0.1, 'max_iter': 1000} → Score = 0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.047e-04, tolerance: 6.306e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e-03, tolerance: 8.707e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e-03, tolerance: 1.049e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e-03, tolerance: 1.200e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e-03, tolerance: 1.331e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e-03, tolerance: 1.407e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e-03, tolerance: 1.470e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e-03, tolerance: 1.583e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e-03, tolerance: 1.717e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e-03, tolerance: 2.505e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.466e-03, tolerance: 2.613e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.551e-03, tolerance: 2.614e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.074e-03, tolerance: 2.629e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.499e-03, tolerance: 2.635e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.337e-03, tolerance: 2.685e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.506e-03, tolerance: 2.845e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.702e-03, tolerance: 3.084e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.418e-03, tolerance: 3.706e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.974e-03, tolerance: 4.463e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.258e-03, tolerance: 5.207e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e-02, tolerance: 5.902e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-02, tolerance: 6.658e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e-02, tolerance: 7.521e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e-02, tolerance: 8.479e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.656e-02, tolerance: 9.357e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e-02, tolerance: 1.077e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e-02, tolerance: 1.180e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e-02, tolerance: 1.255e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] Params {'alpha': 0.1, 'max_iter': 5000} → Score = 0.0876\n",
      "[GridSearch] Params {'alpha': 0.1, 'max_iter': 10000} → Score = 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e-03, tolerance: 6.306e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e-03, tolerance: 8.707e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e-03, tolerance: 1.049e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e-03, tolerance: 1.200e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e-03, tolerance: 1.331e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e-03, tolerance: 1.407e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e-03, tolerance: 1.470e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.966e-03, tolerance: 1.583e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e-03, tolerance: 1.717e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-03, tolerance: 1.818e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e-03, tolerance: 1.975e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e-03, tolerance: 2.291e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e-03, tolerance: 2.505e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.287e-03, tolerance: 2.568e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e-03, tolerance: 2.606e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.336e-03, tolerance: 2.613e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.074e-03, tolerance: 2.629e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.305e-03, tolerance: 2.635e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.190e-03, tolerance: 2.685e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.496e-03, tolerance: 2.845e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.897e-03, tolerance: 3.706e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e-02, tolerance: 4.463e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e-02, tolerance: 5.207e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e-02, tolerance: 5.902e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e-02, tolerance: 6.658e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.706e-02, tolerance: 7.521e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-02, tolerance: 8.479e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e-02, tolerance: 9.357e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e-02, tolerance: 1.077e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.113e-02, tolerance: 1.180e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e-02, tolerance: 1.255e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearch] Params {'alpha': 1, 'max_iter': 1000} → Score = 0.0680\n",
      "[GridSearch] Params {'alpha': 1, 'max_iter': 5000} → Score = 0.0559\n",
      "[GridSearch] Params {'alpha': 1, 'max_iter': 10000} → Score = 0.0559\n",
      "[GridSearch] Params {'alpha': 10, 'max_iter': 1000} → Score = 0.0627\n",
      "[GridSearch] Params {'alpha': 10, 'max_iter': 5000} → Score = 0.0628\n",
      "[GridSearch] Params {'alpha': 10, 'max_iter': 10000} → Score = 0.0628\n",
      "[GridSearch] Params {'alpha': 50, 'max_iter': 1000} → Score = 0.0743\n",
      "[GridSearch] Params {'alpha': 50, 'max_iter': 5000} → Score = 0.0743\n",
      "[GridSearch] Params {'alpha': 50, 'max_iter': 10000} → Score = 0.0743\n",
      "[GridSearch] Params {'alpha': 100, 'max_iter': 1000} → Score = 0.0818\n",
      "[GridSearch] Params {'alpha': 100, 'max_iter': 5000} → Score = 0.0818\n",
      "[GridSearch] Params {'alpha': 100, 'max_iter': 10000} → Score = 0.0818\n",
      "\n",
      "Best Parameters (Lasso): {'alpha': np.float64(1.0), 'max_iter': np.float64(5000.0)}\n",
      "Best Score: 0.055914448365105264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.096327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.104543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.104626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.104579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.123476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.123540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.106785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.087618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.080142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.068039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.055914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.055914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.062654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.062815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.062815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.074349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50.000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.074349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.074349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.081783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100.000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.081783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.081783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha  max_iter     score\n",
       "0     0.001      1000  0.096327\n",
       "1     0.001      5000  0.104543\n",
       "2     0.001     10000  0.104626\n",
       "3     0.010      1000  0.104579\n",
       "4     0.010      5000  0.123476\n",
       "5     0.010     10000  0.123540\n",
       "6     0.100      1000  0.106785\n",
       "7     0.100      5000  0.087618\n",
       "8     0.100     10000  0.080142\n",
       "9     1.000      1000  0.068039\n",
       "10    1.000      5000  0.055914\n",
       "11    1.000     10000  0.055914\n",
       "12   10.000      1000  0.062654\n",
       "13   10.000      5000  0.062815\n",
       "14   10.000     10000  0.062815\n",
       "15   50.000      1000  0.074349\n",
       "16   50.000      5000  0.074349\n",
       "17   50.000     10000  0.074349\n",
       "18  100.000      1000  0.081783\n",
       "19  100.000      5000  0.081783\n",
       "20  100.000     10000  0.081783"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [0.001, 0.01, 0.1, 1, 10, 50, 100],\n",
    "    \"max_iter\": [1000, 5000, 10000],\n",
    "}\n",
    "\n",
    "best_params, best_score, results_df = expanding_window_grid_search(\n",
    "    Lasso,\n",
    "    param_grid,\n",
    "    X,\n",
    "    y,\n",
    "    initial_train_size=10,\n",
    "    horizon=1,\n",
    "    step=1\n",
    ")\n",
    "\n",
    "print(\"\\nBest Parameters (Lasso):\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d8bce0b-b22b-413a-91b6-fda999d1e6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Homicide</th>\n",
       "      <th>Assault</th>\n",
       "      <th>Sexual offences</th>\n",
       "      <th>Harm or endanger persons</th>\n",
       "      <th>Robbery, blackmail, and extortion</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Theft</th>\n",
       "      <th>Fraud and related offences</th>\n",
       "      <th>Drug offences</th>\n",
       "      <th>...</th>\n",
       "      <th>Property damage</th>\n",
       "      <th>Public order, health, and safety offences</th>\n",
       "      <th>Traffic and vehicle offences</th>\n",
       "      <th>Offences against justice procedures and orders</th>\n",
       "      <th>Offences against government</th>\n",
       "      <th>Environmental offences</th>\n",
       "      <th>Miscellaneous offences</th>\n",
       "      <th>Total</th>\n",
       "      <th>Population</th>\n",
       "      <th>Crime_Index_Lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>353</td>\n",
       "      <td>7208</td>\n",
       "      <td>1401</td>\n",
       "      <td>2176</td>\n",
       "      <td>426</td>\n",
       "      <td>11893</td>\n",
       "      <td>29103</td>\n",
       "      <td>19794</td>\n",
       "      <td>7839</td>\n",
       "      <td>...</td>\n",
       "      <td>4290</td>\n",
       "      <td>28539</td>\n",
       "      <td>173948</td>\n",
       "      <td>27664</td>\n",
       "      <td>1376</td>\n",
       "      <td>3521</td>\n",
       "      <td>9651</td>\n",
       "      <td>331751</td>\n",
       "      <td>3112900</td>\n",
       "      <td>10.657297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>366</td>\n",
       "      <td>7933</td>\n",
       "      <td>1092</td>\n",
       "      <td>2299</td>\n",
       "      <td>494</td>\n",
       "      <td>12974</td>\n",
       "      <td>29654</td>\n",
       "      <td>25007</td>\n",
       "      <td>8340</td>\n",
       "      <td>...</td>\n",
       "      <td>4938</td>\n",
       "      <td>22637</td>\n",
       "      <td>142990</td>\n",
       "      <td>17981</td>\n",
       "      <td>2027</td>\n",
       "      <td>3360</td>\n",
       "      <td>9836</td>\n",
       "      <td>294409</td>\n",
       "      <td>3124900</td>\n",
       "      <td>10.657297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982</td>\n",
       "      <td>329</td>\n",
       "      <td>7760</td>\n",
       "      <td>1298</td>\n",
       "      <td>2231</td>\n",
       "      <td>504</td>\n",
       "      <td>14387</td>\n",
       "      <td>32682</td>\n",
       "      <td>26131</td>\n",
       "      <td>9518</td>\n",
       "      <td>...</td>\n",
       "      <td>4914</td>\n",
       "      <td>18268</td>\n",
       "      <td>104739</td>\n",
       "      <td>13957</td>\n",
       "      <td>1203</td>\n",
       "      <td>4025</td>\n",
       "      <td>7878</td>\n",
       "      <td>252119</td>\n",
       "      <td>3156100</td>\n",
       "      <td>9.421389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>407</td>\n",
       "      <td>8741</td>\n",
       "      <td>1449</td>\n",
       "      <td>2693</td>\n",
       "      <td>657</td>\n",
       "      <td>13851</td>\n",
       "      <td>32304</td>\n",
       "      <td>28481</td>\n",
       "      <td>10346</td>\n",
       "      <td>...</td>\n",
       "      <td>5323</td>\n",
       "      <td>16067</td>\n",
       "      <td>105649</td>\n",
       "      <td>15332</td>\n",
       "      <td>736</td>\n",
       "      <td>2252</td>\n",
       "      <td>7774</td>\n",
       "      <td>254658</td>\n",
       "      <td>3199300</td>\n",
       "      <td>7.988308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>406</td>\n",
       "      <td>9349</td>\n",
       "      <td>1682</td>\n",
       "      <td>2651</td>\n",
       "      <td>729</td>\n",
       "      <td>13905</td>\n",
       "      <td>33492</td>\n",
       "      <td>28069</td>\n",
       "      <td>12819</td>\n",
       "      <td>...</td>\n",
       "      <td>5727</td>\n",
       "      <td>17456</td>\n",
       "      <td>116414</td>\n",
       "      <td>16389</td>\n",
       "      <td>1300</td>\n",
       "      <td>2235</td>\n",
       "      <td>8552</td>\n",
       "      <td>274022</td>\n",
       "      <td>3227100</td>\n",
       "      <td>7.959804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>447</td>\n",
       "      <td>9671</td>\n",
       "      <td>1816</td>\n",
       "      <td>2901</td>\n",
       "      <td>997</td>\n",
       "      <td>13685</td>\n",
       "      <td>36226</td>\n",
       "      <td>28449</td>\n",
       "      <td>13519</td>\n",
       "      <td>...</td>\n",
       "      <td>5870</td>\n",
       "      <td>18512</td>\n",
       "      <td>109164</td>\n",
       "      <td>16894</td>\n",
       "      <td>895</td>\n",
       "      <td>2497</td>\n",
       "      <td>7561</td>\n",
       "      <td>272657</td>\n",
       "      <td>3247100</td>\n",
       "      <td>8.491277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1986</td>\n",
       "      <td>464</td>\n",
       "      <td>10244</td>\n",
       "      <td>1917</td>\n",
       "      <td>3143</td>\n",
       "      <td>970</td>\n",
       "      <td>12914</td>\n",
       "      <td>36251</td>\n",
       "      <td>26475</td>\n",
       "      <td>15461</td>\n",
       "      <td>...</td>\n",
       "      <td>6543</td>\n",
       "      <td>18856</td>\n",
       "      <td>130905</td>\n",
       "      <td>18638</td>\n",
       "      <td>1059</td>\n",
       "      <td>2839</td>\n",
       "      <td>7553</td>\n",
       "      <td>298086</td>\n",
       "      <td>3246300</td>\n",
       "      <td>8.396939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1987</td>\n",
       "      <td>485</td>\n",
       "      <td>11476</td>\n",
       "      <td>2180</td>\n",
       "      <td>3204</td>\n",
       "      <td>864</td>\n",
       "      <td>12892</td>\n",
       "      <td>36111</td>\n",
       "      <td>27397</td>\n",
       "      <td>15045</td>\n",
       "      <td>...</td>\n",
       "      <td>5878</td>\n",
       "      <td>15250</td>\n",
       "      <td>126879</td>\n",
       "      <td>20656</td>\n",
       "      <td>475</td>\n",
       "      <td>2789</td>\n",
       "      <td>6921</td>\n",
       "      <td>292500</td>\n",
       "      <td>3274400</td>\n",
       "      <td>9.182331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1988</td>\n",
       "      <td>529</td>\n",
       "      <td>12469</td>\n",
       "      <td>2440</td>\n",
       "      <td>3346</td>\n",
       "      <td>933</td>\n",
       "      <td>12233</td>\n",
       "      <td>34175</td>\n",
       "      <td>29323</td>\n",
       "      <td>15344</td>\n",
       "      <td>...</td>\n",
       "      <td>6545</td>\n",
       "      <td>15706</td>\n",
       "      <td>136190</td>\n",
       "      <td>25120</td>\n",
       "      <td>406</td>\n",
       "      <td>2523</td>\n",
       "      <td>7362</td>\n",
       "      <td>308817</td>\n",
       "      <td>3283400</td>\n",
       "      <td>8.932934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1989</td>\n",
       "      <td>603</td>\n",
       "      <td>11567</td>\n",
       "      <td>2442</td>\n",
       "      <td>3265</td>\n",
       "      <td>812</td>\n",
       "      <td>11081</td>\n",
       "      <td>30824</td>\n",
       "      <td>26463</td>\n",
       "      <td>13399</td>\n",
       "      <td>...</td>\n",
       "      <td>5481</td>\n",
       "      <td>11661</td>\n",
       "      <td>112891</td>\n",
       "      <td>26350</td>\n",
       "      <td>246</td>\n",
       "      <td>2627</td>\n",
       "      <td>7561</td>\n",
       "      <td>270585</td>\n",
       "      <td>3299200</td>\n",
       "      <td>9.405403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1990</td>\n",
       "      <td>552</td>\n",
       "      <td>11739</td>\n",
       "      <td>2986</td>\n",
       "      <td>3773</td>\n",
       "      <td>966</td>\n",
       "      <td>11140</td>\n",
       "      <td>31494</td>\n",
       "      <td>25117</td>\n",
       "      <td>14508</td>\n",
       "      <td>...</td>\n",
       "      <td>5713</td>\n",
       "      <td>10384</td>\n",
       "      <td>80170</td>\n",
       "      <td>27777</td>\n",
       "      <td>184</td>\n",
       "      <td>2776</td>\n",
       "      <td>8153</td>\n",
       "      <td>241026</td>\n",
       "      <td>3329800</td>\n",
       "      <td>8.201534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1991</td>\n",
       "      <td>489</td>\n",
       "      <td>12581</td>\n",
       "      <td>3671</td>\n",
       "      <td>3797</td>\n",
       "      <td>1110</td>\n",
       "      <td>12229</td>\n",
       "      <td>33859</td>\n",
       "      <td>31062</td>\n",
       "      <td>14814</td>\n",
       "      <td>...</td>\n",
       "      <td>6019</td>\n",
       "      <td>11179</td>\n",
       "      <td>79441</td>\n",
       "      <td>29186</td>\n",
       "      <td>738</td>\n",
       "      <td>3015</td>\n",
       "      <td>9192</td>\n",
       "      <td>255878</td>\n",
       "      <td>3495100</td>\n",
       "      <td>7.238453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1992</td>\n",
       "      <td>439</td>\n",
       "      <td>14432</td>\n",
       "      <td>4813</td>\n",
       "      <td>4394</td>\n",
       "      <td>1326</td>\n",
       "      <td>11936</td>\n",
       "      <td>33625</td>\n",
       "      <td>38497</td>\n",
       "      <td>16290</td>\n",
       "      <td>...</td>\n",
       "      <td>5962</td>\n",
       "      <td>11134</td>\n",
       "      <td>67593</td>\n",
       "      <td>29444</td>\n",
       "      <td>209</td>\n",
       "      <td>3862</td>\n",
       "      <td>11027</td>\n",
       "      <td>258491</td>\n",
       "      <td>3531700</td>\n",
       "      <td>7.321049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1993</td>\n",
       "      <td>359</td>\n",
       "      <td>17817</td>\n",
       "      <td>5424</td>\n",
       "      <td>4688</td>\n",
       "      <td>1431</td>\n",
       "      <td>11921</td>\n",
       "      <td>32392</td>\n",
       "      <td>36355</td>\n",
       "      <td>18429</td>\n",
       "      <td>...</td>\n",
       "      <td>6673</td>\n",
       "      <td>12851</td>\n",
       "      <td>63973</td>\n",
       "      <td>29023</td>\n",
       "      <td>166</td>\n",
       "      <td>5127</td>\n",
       "      <td>10760</td>\n",
       "      <td>261371</td>\n",
       "      <td>3572200</td>\n",
       "      <td>7.319166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1994</td>\n",
       "      <td>379</td>\n",
       "      <td>22497</td>\n",
       "      <td>5372</td>\n",
       "      <td>5675</td>\n",
       "      <td>1668</td>\n",
       "      <td>11851</td>\n",
       "      <td>33222</td>\n",
       "      <td>39553</td>\n",
       "      <td>17987</td>\n",
       "      <td>...</td>\n",
       "      <td>8823</td>\n",
       "      <td>14306</td>\n",
       "      <td>62108</td>\n",
       "      <td>31219</td>\n",
       "      <td>168</td>\n",
       "      <td>2269</td>\n",
       "      <td>10835</td>\n",
       "      <td>271906</td>\n",
       "      <td>3620000</td>\n",
       "      <td>7.316808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1995</td>\n",
       "      <td>417</td>\n",
       "      <td>22589</td>\n",
       "      <td>5334</td>\n",
       "      <td>5942</td>\n",
       "      <td>1792</td>\n",
       "      <td>11639</td>\n",
       "      <td>32879</td>\n",
       "      <td>39456</td>\n",
       "      <td>16627</td>\n",
       "      <td>...</td>\n",
       "      <td>8446</td>\n",
       "      <td>15919</td>\n",
       "      <td>66707</td>\n",
       "      <td>31757</td>\n",
       "      <td>219</td>\n",
       "      <td>2295</td>\n",
       "      <td>11028</td>\n",
       "      <td>276802</td>\n",
       "      <td>3673400</td>\n",
       "      <td>7.511215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1996</td>\n",
       "      <td>412</td>\n",
       "      <td>20994</td>\n",
       "      <td>5280</td>\n",
       "      <td>5843</td>\n",
       "      <td>1699</td>\n",
       "      <td>13322</td>\n",
       "      <td>33609</td>\n",
       "      <td>35201</td>\n",
       "      <td>17796</td>\n",
       "      <td>...</td>\n",
       "      <td>8465</td>\n",
       "      <td>16319</td>\n",
       "      <td>64427</td>\n",
       "      <td>32786</td>\n",
       "      <td>334</td>\n",
       "      <td>1715</td>\n",
       "      <td>6823</td>\n",
       "      <td>269061</td>\n",
       "      <td>3732000</td>\n",
       "      <td>7.535308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1997</td>\n",
       "      <td>438</td>\n",
       "      <td>21480</td>\n",
       "      <td>5175</td>\n",
       "      <td>5380</td>\n",
       "      <td>2048</td>\n",
       "      <td>11813</td>\n",
       "      <td>33390</td>\n",
       "      <td>33081</td>\n",
       "      <td>20063</td>\n",
       "      <td>...</td>\n",
       "      <td>8671</td>\n",
       "      <td>17487</td>\n",
       "      <td>63213</td>\n",
       "      <td>33908</td>\n",
       "      <td>274</td>\n",
       "      <td>1979</td>\n",
       "      <td>3860</td>\n",
       "      <td>266665</td>\n",
       "      <td>3781300</td>\n",
       "      <td>7.209566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1998</td>\n",
       "      <td>337</td>\n",
       "      <td>21003</td>\n",
       "      <td>4686</td>\n",
       "      <td>5665</td>\n",
       "      <td>1872</td>\n",
       "      <td>11700</td>\n",
       "      <td>34038</td>\n",
       "      <td>32522</td>\n",
       "      <td>20970</td>\n",
       "      <td>...</td>\n",
       "      <td>8915</td>\n",
       "      <td>19249</td>\n",
       "      <td>64984</td>\n",
       "      <td>35583</td>\n",
       "      <td>317</td>\n",
       "      <td>2035</td>\n",
       "      <td>3989</td>\n",
       "      <td>272436</td>\n",
       "      <td>3815000</td>\n",
       "      <td>7.052204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1999</td>\n",
       "      <td>267</td>\n",
       "      <td>20202</td>\n",
       "      <td>4271</td>\n",
       "      <td>5726</td>\n",
       "      <td>1641</td>\n",
       "      <td>11730</td>\n",
       "      <td>33320</td>\n",
       "      <td>31271</td>\n",
       "      <td>20454</td>\n",
       "      <td>...</td>\n",
       "      <td>9110</td>\n",
       "      <td>19105</td>\n",
       "      <td>55917</td>\n",
       "      <td>40094</td>\n",
       "      <td>294</td>\n",
       "      <td>1817</td>\n",
       "      <td>2547</td>\n",
       "      <td>262059</td>\n",
       "      <td>3835100</td>\n",
       "      <td>7.141180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2000</td>\n",
       "      <td>185</td>\n",
       "      <td>21708</td>\n",
       "      <td>4514</td>\n",
       "      <td>5885</td>\n",
       "      <td>1758</td>\n",
       "      <td>11894</td>\n",
       "      <td>34000</td>\n",
       "      <td>32504</td>\n",
       "      <td>20132</td>\n",
       "      <td>...</td>\n",
       "      <td>9599</td>\n",
       "      <td>19660</td>\n",
       "      <td>53578</td>\n",
       "      <td>41897</td>\n",
       "      <td>360</td>\n",
       "      <td>2325</td>\n",
       "      <td>2184</td>\n",
       "      <td>266422</td>\n",
       "      <td>3857700</td>\n",
       "      <td>6.833173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2001</td>\n",
       "      <td>217</td>\n",
       "      <td>20809</td>\n",
       "      <td>4492</td>\n",
       "      <td>5759</td>\n",
       "      <td>1412</td>\n",
       "      <td>11055</td>\n",
       "      <td>32184</td>\n",
       "      <td>30519</td>\n",
       "      <td>18120</td>\n",
       "      <td>...</td>\n",
       "      <td>9156</td>\n",
       "      <td>19348</td>\n",
       "      <td>52185</td>\n",
       "      <td>40607</td>\n",
       "      <td>476</td>\n",
       "      <td>2524</td>\n",
       "      <td>2609</td>\n",
       "      <td>255739</td>\n",
       "      <td>3880500</td>\n",
       "      <td>6.906239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2002</td>\n",
       "      <td>224</td>\n",
       "      <td>21720</td>\n",
       "      <td>4582</td>\n",
       "      <td>6391</td>\n",
       "      <td>1686</td>\n",
       "      <td>10463</td>\n",
       "      <td>33413</td>\n",
       "      <td>32357</td>\n",
       "      <td>19333</td>\n",
       "      <td>...</td>\n",
       "      <td>9025</td>\n",
       "      <td>21305</td>\n",
       "      <td>51900</td>\n",
       "      <td>40582</td>\n",
       "      <td>359</td>\n",
       "      <td>2467</td>\n",
       "      <td>4545</td>\n",
       "      <td>265322</td>\n",
       "      <td>3948500</td>\n",
       "      <td>6.590362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2003</td>\n",
       "      <td>235</td>\n",
       "      <td>23051</td>\n",
       "      <td>5050</td>\n",
       "      <td>7040</td>\n",
       "      <td>1921</td>\n",
       "      <td>11524</td>\n",
       "      <td>35171</td>\n",
       "      <td>30856</td>\n",
       "      <td>19561</td>\n",
       "      <td>...</td>\n",
       "      <td>9930</td>\n",
       "      <td>26405</td>\n",
       "      <td>56560</td>\n",
       "      <td>44004</td>\n",
       "      <td>656</td>\n",
       "      <td>2651</td>\n",
       "      <td>2834</td>\n",
       "      <td>282515</td>\n",
       "      <td>4027200</td>\n",
       "      <td>6.719564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2004</td>\n",
       "      <td>235</td>\n",
       "      <td>24560</td>\n",
       "      <td>4882</td>\n",
       "      <td>7277</td>\n",
       "      <td>1886</td>\n",
       "      <td>12288</td>\n",
       "      <td>35587</td>\n",
       "      <td>30996</td>\n",
       "      <td>18680</td>\n",
       "      <td>...</td>\n",
       "      <td>10401</td>\n",
       "      <td>25165</td>\n",
       "      <td>58142</td>\n",
       "      <td>46630</td>\n",
       "      <td>526</td>\n",
       "      <td>2329</td>\n",
       "      <td>2814</td>\n",
       "      <td>287754</td>\n",
       "      <td>4087500</td>\n",
       "      <td>7.015172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2005</td>\n",
       "      <td>211</td>\n",
       "      <td>25602</td>\n",
       "      <td>5032</td>\n",
       "      <td>7650</td>\n",
       "      <td>2166</td>\n",
       "      <td>12866</td>\n",
       "      <td>36453</td>\n",
       "      <td>30429</td>\n",
       "      <td>18078</td>\n",
       "      <td>...</td>\n",
       "      <td>11803</td>\n",
       "      <td>26527</td>\n",
       "      <td>60892</td>\n",
       "      <td>47437</td>\n",
       "      <td>596</td>\n",
       "      <td>1889</td>\n",
       "      <td>3107</td>\n",
       "      <td>297185</td>\n",
       "      <td>4133900</td>\n",
       "      <td>7.039853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2006</td>\n",
       "      <td>215</td>\n",
       "      <td>26625</td>\n",
       "      <td>5005</td>\n",
       "      <td>7835</td>\n",
       "      <td>2345</td>\n",
       "      <td>12305</td>\n",
       "      <td>36106</td>\n",
       "      <td>31985</td>\n",
       "      <td>18861</td>\n",
       "      <td>...</td>\n",
       "      <td>12079</td>\n",
       "      <td>29408</td>\n",
       "      <td>66361</td>\n",
       "      <td>52249</td>\n",
       "      <td>597</td>\n",
       "      <td>1771</td>\n",
       "      <td>4216</td>\n",
       "      <td>314727</td>\n",
       "      <td>4184600</td>\n",
       "      <td>7.188974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2007</td>\n",
       "      <td>233</td>\n",
       "      <td>31338</td>\n",
       "      <td>4923</td>\n",
       "      <td>8490</td>\n",
       "      <td>2360</td>\n",
       "      <td>12047</td>\n",
       "      <td>36520</td>\n",
       "      <td>29786</td>\n",
       "      <td>19627</td>\n",
       "      <td>...</td>\n",
       "      <td>13649</td>\n",
       "      <td>31920</td>\n",
       "      <td>71251</td>\n",
       "      <td>58989</td>\n",
       "      <td>487</td>\n",
       "      <td>2242</td>\n",
       "      <td>2418</td>\n",
       "      <td>333004</td>\n",
       "      <td>4223800</td>\n",
       "      <td>7.521077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2008</td>\n",
       "      <td>247</td>\n",
       "      <td>33233</td>\n",
       "      <td>4952</td>\n",
       "      <td>9041</td>\n",
       "      <td>2418</td>\n",
       "      <td>12994</td>\n",
       "      <td>36583</td>\n",
       "      <td>33088</td>\n",
       "      <td>22295</td>\n",
       "      <td>...</td>\n",
       "      <td>13372</td>\n",
       "      <td>33687</td>\n",
       "      <td>72326</td>\n",
       "      <td>63015</td>\n",
       "      <td>493</td>\n",
       "      <td>2154</td>\n",
       "      <td>1826</td>\n",
       "      <td>348638</td>\n",
       "      <td>4259800</td>\n",
       "      <td>7.883991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2009</td>\n",
       "      <td>243</td>\n",
       "      <td>33928</td>\n",
       "      <td>5661</td>\n",
       "      <td>9217</td>\n",
       "      <td>2296</td>\n",
       "      <td>12444</td>\n",
       "      <td>36227</td>\n",
       "      <td>27615</td>\n",
       "      <td>24941</td>\n",
       "      <td>...</td>\n",
       "      <td>13594</td>\n",
       "      <td>33282</td>\n",
       "      <td>69451</td>\n",
       "      <td>66248</td>\n",
       "      <td>703</td>\n",
       "      <td>2517</td>\n",
       "      <td>1679</td>\n",
       "      <td>346707</td>\n",
       "      <td>4302600</td>\n",
       "      <td>8.184375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2010</td>\n",
       "      <td>221</td>\n",
       "      <td>31124</td>\n",
       "      <td>5402</td>\n",
       "      <td>8423</td>\n",
       "      <td>1797</td>\n",
       "      <td>10782</td>\n",
       "      <td>31206</td>\n",
       "      <td>26843</td>\n",
       "      <td>21931</td>\n",
       "      <td>...</td>\n",
       "      <td>11633</td>\n",
       "      <td>23069</td>\n",
       "      <td>61230</td>\n",
       "      <td>64581</td>\n",
       "      <td>847</td>\n",
       "      <td>2286</td>\n",
       "      <td>1551</td>\n",
       "      <td>308540</td>\n",
       "      <td>4350700</td>\n",
       "      <td>8.058081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2011</td>\n",
       "      <td>154</td>\n",
       "      <td>28976</td>\n",
       "      <td>5416</td>\n",
       "      <td>7512</td>\n",
       "      <td>1902</td>\n",
       "      <td>10705</td>\n",
       "      <td>29668</td>\n",
       "      <td>26379</td>\n",
       "      <td>19633</td>\n",
       "      <td>...</td>\n",
       "      <td>11102</td>\n",
       "      <td>15629</td>\n",
       "      <td>57370</td>\n",
       "      <td>61717</td>\n",
       "      <td>532</td>\n",
       "      <td>1692</td>\n",
       "      <td>1382</td>\n",
       "      <td>284899</td>\n",
       "      <td>4384000</td>\n",
       "      <td>7.091732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2012</td>\n",
       "      <td>163</td>\n",
       "      <td>27725</td>\n",
       "      <td>6199</td>\n",
       "      <td>7198</td>\n",
       "      <td>1725</td>\n",
       "      <td>10036</td>\n",
       "      <td>28241</td>\n",
       "      <td>26080</td>\n",
       "      <td>20184</td>\n",
       "      <td>...</td>\n",
       "      <td>10238</td>\n",
       "      <td>14220</td>\n",
       "      <td>52645</td>\n",
       "      <td>57760</td>\n",
       "      <td>582</td>\n",
       "      <td>2649</td>\n",
       "      <td>1410</td>\n",
       "      <td>272250</td>\n",
       "      <td>4408100</td>\n",
       "      <td>6.498609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013</td>\n",
       "      <td>240</td>\n",
       "      <td>22753</td>\n",
       "      <td>5578</td>\n",
       "      <td>6180</td>\n",
       "      <td>1456</td>\n",
       "      <td>8234</td>\n",
       "      <td>25433</td>\n",
       "      <td>21062</td>\n",
       "      <td>15286</td>\n",
       "      <td>...</td>\n",
       "      <td>8504</td>\n",
       "      <td>10790</td>\n",
       "      <td>46258</td>\n",
       "      <td>49758</td>\n",
       "      <td>533</td>\n",
       "      <td>1964</td>\n",
       "      <td>1038</td>\n",
       "      <td>229410</td>\n",
       "      <td>4442100</td>\n",
       "      <td>6.176130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014</td>\n",
       "      <td>207</td>\n",
       "      <td>22340</td>\n",
       "      <td>5942</td>\n",
       "      <td>6600</td>\n",
       "      <td>1344</td>\n",
       "      <td>7363</td>\n",
       "      <td>23543</td>\n",
       "      <td>19763</td>\n",
       "      <td>14521</td>\n",
       "      <td>...</td>\n",
       "      <td>7692</td>\n",
       "      <td>9719</td>\n",
       "      <td>41929</td>\n",
       "      <td>49634</td>\n",
       "      <td>430</td>\n",
       "      <td>1885</td>\n",
       "      <td>864</td>\n",
       "      <td>218170</td>\n",
       "      <td>4516500</td>\n",
       "      <td>5.164449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2015</td>\n",
       "      <td>236</td>\n",
       "      <td>24225</td>\n",
       "      <td>6284</td>\n",
       "      <td>7127</td>\n",
       "      <td>1350</td>\n",
       "      <td>7398</td>\n",
       "      <td>24968</td>\n",
       "      <td>17184</td>\n",
       "      <td>14957</td>\n",
       "      <td>...</td>\n",
       "      <td>7946</td>\n",
       "      <td>7775</td>\n",
       "      <td>40610</td>\n",
       "      <td>52333</td>\n",
       "      <td>617</td>\n",
       "      <td>1667</td>\n",
       "      <td>862</td>\n",
       "      <td>220185</td>\n",
       "      <td>4609400</td>\n",
       "      <td>4.830510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016</td>\n",
       "      <td>202</td>\n",
       "      <td>24890</td>\n",
       "      <td>5270</td>\n",
       "      <td>7651</td>\n",
       "      <td>1717</td>\n",
       "      <td>7455</td>\n",
       "      <td>25873</td>\n",
       "      <td>17682</td>\n",
       "      <td>15369</td>\n",
       "      <td>...</td>\n",
       "      <td>7835</td>\n",
       "      <td>7830</td>\n",
       "      <td>42561</td>\n",
       "      <td>53540</td>\n",
       "      <td>626</td>\n",
       "      <td>1364</td>\n",
       "      <td>731</td>\n",
       "      <td>225931</td>\n",
       "      <td>4714100</td>\n",
       "      <td>4.776869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017</td>\n",
       "      <td>241</td>\n",
       "      <td>24514</td>\n",
       "      <td>6177</td>\n",
       "      <td>7396</td>\n",
       "      <td>1795</td>\n",
       "      <td>6647</td>\n",
       "      <td>25733</td>\n",
       "      <td>16137</td>\n",
       "      <td>16202</td>\n",
       "      <td>...</td>\n",
       "      <td>7455</td>\n",
       "      <td>7091</td>\n",
       "      <td>42320</td>\n",
       "      <td>51641</td>\n",
       "      <td>499</td>\n",
       "      <td>1760</td>\n",
       "      <td>666</td>\n",
       "      <td>221757</td>\n",
       "      <td>4813600</td>\n",
       "      <td>4.792665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>235</td>\n",
       "      <td>23673</td>\n",
       "      <td>5519</td>\n",
       "      <td>7521</td>\n",
       "      <td>1743</td>\n",
       "      <td>5924</td>\n",
       "      <td>24824</td>\n",
       "      <td>13759</td>\n",
       "      <td>14694</td>\n",
       "      <td>...</td>\n",
       "      <td>7228</td>\n",
       "      <td>6574</td>\n",
       "      <td>41148</td>\n",
       "      <td>51313</td>\n",
       "      <td>670</td>\n",
       "      <td>1759</td>\n",
       "      <td>839</td>\n",
       "      <td>212872</td>\n",
       "      <td>4900600</td>\n",
       "      <td>4.606885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>211</td>\n",
       "      <td>23545</td>\n",
       "      <td>5216</td>\n",
       "      <td>7521</td>\n",
       "      <td>1401</td>\n",
       "      <td>6054</td>\n",
       "      <td>25469</td>\n",
       "      <td>11752</td>\n",
       "      <td>14984</td>\n",
       "      <td>...</td>\n",
       "      <td>7091</td>\n",
       "      <td>6098</td>\n",
       "      <td>36957</td>\n",
       "      <td>49373</td>\n",
       "      <td>745</td>\n",
       "      <td>1496</td>\n",
       "      <td>782</td>\n",
       "      <td>204566</td>\n",
       "      <td>4979200</td>\n",
       "      <td>4.343795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020</td>\n",
       "      <td>339</td>\n",
       "      <td>25701</td>\n",
       "      <td>6238</td>\n",
       "      <td>8263</td>\n",
       "      <td>1328</td>\n",
       "      <td>5894</td>\n",
       "      <td>25310</td>\n",
       "      <td>12465</td>\n",
       "      <td>14736</td>\n",
       "      <td>...</td>\n",
       "      <td>7352</td>\n",
       "      <td>6414</td>\n",
       "      <td>40876</td>\n",
       "      <td>47544</td>\n",
       "      <td>877</td>\n",
       "      <td>1353</td>\n",
       "      <td>784</td>\n",
       "      <td>212064</td>\n",
       "      <td>5090200</td>\n",
       "      <td>4.108411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021</td>\n",
       "      <td>245</td>\n",
       "      <td>20540</td>\n",
       "      <td>6010</td>\n",
       "      <td>7330</td>\n",
       "      <td>1156</td>\n",
       "      <td>5008</td>\n",
       "      <td>20427</td>\n",
       "      <td>9290</td>\n",
       "      <td>12081</td>\n",
       "      <td>...</td>\n",
       "      <td>5646</td>\n",
       "      <td>5742</td>\n",
       "      <td>33083</td>\n",
       "      <td>34146</td>\n",
       "      <td>313</td>\n",
       "      <td>1074</td>\n",
       "      <td>531</td>\n",
       "      <td>168188</td>\n",
       "      <td>5111300</td>\n",
       "      <td>4.166123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022</td>\n",
       "      <td>227</td>\n",
       "      <td>22599</td>\n",
       "      <td>7175</td>\n",
       "      <td>8140</td>\n",
       "      <td>1235</td>\n",
       "      <td>5664</td>\n",
       "      <td>26312</td>\n",
       "      <td>8765</td>\n",
       "      <td>12841</td>\n",
       "      <td>...</td>\n",
       "      <td>6578</td>\n",
       "      <td>6619</td>\n",
       "      <td>39634</td>\n",
       "      <td>38123</td>\n",
       "      <td>342</td>\n",
       "      <td>952</td>\n",
       "      <td>657</td>\n",
       "      <td>192313</td>\n",
       "      <td>5117200</td>\n",
       "      <td>3.290513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023</td>\n",
       "      <td>283</td>\n",
       "      <td>24378</td>\n",
       "      <td>7767</td>\n",
       "      <td>9018</td>\n",
       "      <td>1617</td>\n",
       "      <td>7293</td>\n",
       "      <td>34148</td>\n",
       "      <td>8729</td>\n",
       "      <td>13156</td>\n",
       "      <td>...</td>\n",
       "      <td>6860</td>\n",
       "      <td>7673</td>\n",
       "      <td>41639</td>\n",
       "      <td>44380</td>\n",
       "      <td>312</td>\n",
       "      <td>1353</td>\n",
       "      <td>660</td>\n",
       "      <td>216533</td>\n",
       "      <td>5223100</td>\n",
       "      <td>3.758169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2024</td>\n",
       "      <td>297</td>\n",
       "      <td>25427</td>\n",
       "      <td>8428</td>\n",
       "      <td>10024</td>\n",
       "      <td>1583</td>\n",
       "      <td>6835</td>\n",
       "      <td>36179</td>\n",
       "      <td>9317</td>\n",
       "      <td>15791</td>\n",
       "      <td>...</td>\n",
       "      <td>6666</td>\n",
       "      <td>8863</td>\n",
       "      <td>41281</td>\n",
       "      <td>45497</td>\n",
       "      <td>393</td>\n",
       "      <td>1553</td>\n",
       "      <td>591</td>\n",
       "      <td>226317</td>\n",
       "      <td>5269939</td>\n",
       "      <td>4.145680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Homicide  Assault  Sexual offences  Harm or endanger persons  \\\n",
       "0   1980       353     7208             1401                      2176   \n",
       "1   1981       366     7933             1092                      2299   \n",
       "2   1982       329     7760             1298                      2231   \n",
       "3   1983       407     8741             1449                      2693   \n",
       "4   1984       406     9349             1682                      2651   \n",
       "5   1985       447     9671             1816                      2901   \n",
       "6   1986       464    10244             1917                      3143   \n",
       "7   1987       485    11476             2180                      3204   \n",
       "8   1988       529    12469             2440                      3346   \n",
       "9   1989       603    11567             2442                      3265   \n",
       "10  1990       552    11739             2986                      3773   \n",
       "11  1991       489    12581             3671                      3797   \n",
       "12  1992       439    14432             4813                      4394   \n",
       "13  1993       359    17817             5424                      4688   \n",
       "14  1994       379    22497             5372                      5675   \n",
       "15  1995       417    22589             5334                      5942   \n",
       "16  1996       412    20994             5280                      5843   \n",
       "17  1997       438    21480             5175                      5380   \n",
       "18  1998       337    21003             4686                      5665   \n",
       "19  1999       267    20202             4271                      5726   \n",
       "20  2000       185    21708             4514                      5885   \n",
       "21  2001       217    20809             4492                      5759   \n",
       "22  2002       224    21720             4582                      6391   \n",
       "23  2003       235    23051             5050                      7040   \n",
       "24  2004       235    24560             4882                      7277   \n",
       "25  2005       211    25602             5032                      7650   \n",
       "26  2006       215    26625             5005                      7835   \n",
       "27  2007       233    31338             4923                      8490   \n",
       "28  2008       247    33233             4952                      9041   \n",
       "29  2009       243    33928             5661                      9217   \n",
       "30  2010       221    31124             5402                      8423   \n",
       "31  2011       154    28976             5416                      7512   \n",
       "32  2012       163    27725             6199                      7198   \n",
       "33  2013       240    22753             5578                      6180   \n",
       "34  2014       207    22340             5942                      6600   \n",
       "35  2015       236    24225             6284                      7127   \n",
       "36  2016       202    24890             5270                      7651   \n",
       "37  2017       241    24514             6177                      7396   \n",
       "38  2018       235    23673             5519                      7521   \n",
       "39  2019       211    23545             5216                      7521   \n",
       "40  2020       339    25701             6238                      8263   \n",
       "41  2021       245    20540             6010                      7330   \n",
       "42  2022       227    22599             7175                      8140   \n",
       "43  2023       283    24378             7767                      9018   \n",
       "44  2024       297    25427             8428                     10024   \n",
       "\n",
       "    Robbery, blackmail, and extortion  Burglary   Theft  \\\n",
       "0                                 426      11893  29103   \n",
       "1                                 494      12974  29654   \n",
       "2                                 504      14387  32682   \n",
       "3                                 657      13851  32304   \n",
       "4                                 729      13905  33492   \n",
       "5                                 997      13685  36226   \n",
       "6                                 970      12914  36251   \n",
       "7                                 864      12892  36111   \n",
       "8                                 933      12233  34175   \n",
       "9                                 812      11081  30824   \n",
       "10                                966      11140  31494   \n",
       "11                               1110      12229  33859   \n",
       "12                               1326      11936  33625   \n",
       "13                               1431      11921  32392   \n",
       "14                               1668      11851  33222   \n",
       "15                               1792      11639  32879   \n",
       "16                               1699      13322  33609   \n",
       "17                               2048      11813  33390   \n",
       "18                               1872      11700  34038   \n",
       "19                               1641      11730  33320   \n",
       "20                               1758      11894  34000   \n",
       "21                               1412      11055  32184   \n",
       "22                               1686      10463  33413   \n",
       "23                               1921      11524  35171   \n",
       "24                               1886      12288  35587   \n",
       "25                               2166      12866  36453   \n",
       "26                               2345      12305  36106   \n",
       "27                               2360      12047  36520   \n",
       "28                               2418      12994  36583   \n",
       "29                               2296      12444  36227   \n",
       "30                               1797      10782  31206   \n",
       "31                               1902      10705  29668   \n",
       "32                               1725      10036  28241   \n",
       "33                               1456       8234  25433   \n",
       "34                               1344       7363  23543   \n",
       "35                               1350       7398  24968   \n",
       "36                               1717       7455  25873   \n",
       "37                               1795       6647  25733   \n",
       "38                               1743       5924  24824   \n",
       "39                               1401       6054  25469   \n",
       "40                               1328       5894  25310   \n",
       "41                               1156       5008  20427   \n",
       "42                               1235       5664  26312   \n",
       "43                               1617       7293  34148   \n",
       "44                               1583       6835  36179   \n",
       "\n",
       "    Fraud and related offences  Drug offences  ...  Property damage  \\\n",
       "0                        19794           7839  ...             4290   \n",
       "1                        25007           8340  ...             4938   \n",
       "2                        26131           9518  ...             4914   \n",
       "3                        28481          10346  ...             5323   \n",
       "4                        28069          12819  ...             5727   \n",
       "5                        28449          13519  ...             5870   \n",
       "6                        26475          15461  ...             6543   \n",
       "7                        27397          15045  ...             5878   \n",
       "8                        29323          15344  ...             6545   \n",
       "9                        26463          13399  ...             5481   \n",
       "10                       25117          14508  ...             5713   \n",
       "11                       31062          14814  ...             6019   \n",
       "12                       38497          16290  ...             5962   \n",
       "13                       36355          18429  ...             6673   \n",
       "14                       39553          17987  ...             8823   \n",
       "15                       39456          16627  ...             8446   \n",
       "16                       35201          17796  ...             8465   \n",
       "17                       33081          20063  ...             8671   \n",
       "18                       32522          20970  ...             8915   \n",
       "19                       31271          20454  ...             9110   \n",
       "20                       32504          20132  ...             9599   \n",
       "21                       30519          18120  ...             9156   \n",
       "22                       32357          19333  ...             9025   \n",
       "23                       30856          19561  ...             9930   \n",
       "24                       30996          18680  ...            10401   \n",
       "25                       30429          18078  ...            11803   \n",
       "26                       31985          18861  ...            12079   \n",
       "27                       29786          19627  ...            13649   \n",
       "28                       33088          22295  ...            13372   \n",
       "29                       27615          24941  ...            13594   \n",
       "30                       26843          21931  ...            11633   \n",
       "31                       26379          19633  ...            11102   \n",
       "32                       26080          20184  ...            10238   \n",
       "33                       21062          15286  ...             8504   \n",
       "34                       19763          14521  ...             7692   \n",
       "35                       17184          14957  ...             7946   \n",
       "36                       17682          15369  ...             7835   \n",
       "37                       16137          16202  ...             7455   \n",
       "38                       13759          14694  ...             7228   \n",
       "39                       11752          14984  ...             7091   \n",
       "40                       12465          14736  ...             7352   \n",
       "41                        9290          12081  ...             5646   \n",
       "42                        8765          12841  ...             6578   \n",
       "43                        8729          13156  ...             6860   \n",
       "44                        9317          15791  ...             6666   \n",
       "\n",
       "    Public order, health, and safety offences  Traffic and vehicle offences  \\\n",
       "0                                       28539                        173948   \n",
       "1                                       22637                        142990   \n",
       "2                                       18268                        104739   \n",
       "3                                       16067                        105649   \n",
       "4                                       17456                        116414   \n",
       "5                                       18512                        109164   \n",
       "6                                       18856                        130905   \n",
       "7                                       15250                        126879   \n",
       "8                                       15706                        136190   \n",
       "9                                       11661                        112891   \n",
       "10                                      10384                         80170   \n",
       "11                                      11179                         79441   \n",
       "12                                      11134                         67593   \n",
       "13                                      12851                         63973   \n",
       "14                                      14306                         62108   \n",
       "15                                      15919                         66707   \n",
       "16                                      16319                         64427   \n",
       "17                                      17487                         63213   \n",
       "18                                      19249                         64984   \n",
       "19                                      19105                         55917   \n",
       "20                                      19660                         53578   \n",
       "21                                      19348                         52185   \n",
       "22                                      21305                         51900   \n",
       "23                                      26405                         56560   \n",
       "24                                      25165                         58142   \n",
       "25                                      26527                         60892   \n",
       "26                                      29408                         66361   \n",
       "27                                      31920                         71251   \n",
       "28                                      33687                         72326   \n",
       "29                                      33282                         69451   \n",
       "30                                      23069                         61230   \n",
       "31                                      15629                         57370   \n",
       "32                                      14220                         52645   \n",
       "33                                      10790                         46258   \n",
       "34                                       9719                         41929   \n",
       "35                                       7775                         40610   \n",
       "36                                       7830                         42561   \n",
       "37                                       7091                         42320   \n",
       "38                                       6574                         41148   \n",
       "39                                       6098                         36957   \n",
       "40                                       6414                         40876   \n",
       "41                                       5742                         33083   \n",
       "42                                       6619                         39634   \n",
       "43                                       7673                         41639   \n",
       "44                                       8863                         41281   \n",
       "\n",
       "    Offences against justice procedures and orders  \\\n",
       "0                                            27664   \n",
       "1                                            17981   \n",
       "2                                            13957   \n",
       "3                                            15332   \n",
       "4                                            16389   \n",
       "5                                            16894   \n",
       "6                                            18638   \n",
       "7                                            20656   \n",
       "8                                            25120   \n",
       "9                                            26350   \n",
       "10                                           27777   \n",
       "11                                           29186   \n",
       "12                                           29444   \n",
       "13                                           29023   \n",
       "14                                           31219   \n",
       "15                                           31757   \n",
       "16                                           32786   \n",
       "17                                           33908   \n",
       "18                                           35583   \n",
       "19                                           40094   \n",
       "20                                           41897   \n",
       "21                                           40607   \n",
       "22                                           40582   \n",
       "23                                           44004   \n",
       "24                                           46630   \n",
       "25                                           47437   \n",
       "26                                           52249   \n",
       "27                                           58989   \n",
       "28                                           63015   \n",
       "29                                           66248   \n",
       "30                                           64581   \n",
       "31                                           61717   \n",
       "32                                           57760   \n",
       "33                                           49758   \n",
       "34                                           49634   \n",
       "35                                           52333   \n",
       "36                                           53540   \n",
       "37                                           51641   \n",
       "38                                           51313   \n",
       "39                                           49373   \n",
       "40                                           47544   \n",
       "41                                           34146   \n",
       "42                                           38123   \n",
       "43                                           44380   \n",
       "44                                           45497   \n",
       "\n",
       "    Offences against government  Environmental offences  \\\n",
       "0                          1376                    3521   \n",
       "1                          2027                    3360   \n",
       "2                          1203                    4025   \n",
       "3                           736                    2252   \n",
       "4                          1300                    2235   \n",
       "5                           895                    2497   \n",
       "6                          1059                    2839   \n",
       "7                           475                    2789   \n",
       "8                           406                    2523   \n",
       "9                           246                    2627   \n",
       "10                          184                    2776   \n",
       "11                          738                    3015   \n",
       "12                          209                    3862   \n",
       "13                          166                    5127   \n",
       "14                          168                    2269   \n",
       "15                          219                    2295   \n",
       "16                          334                    1715   \n",
       "17                          274                    1979   \n",
       "18                          317                    2035   \n",
       "19                          294                    1817   \n",
       "20                          360                    2325   \n",
       "21                          476                    2524   \n",
       "22                          359                    2467   \n",
       "23                          656                    2651   \n",
       "24                          526                    2329   \n",
       "25                          596                    1889   \n",
       "26                          597                    1771   \n",
       "27                          487                    2242   \n",
       "28                          493                    2154   \n",
       "29                          703                    2517   \n",
       "30                          847                    2286   \n",
       "31                          532                    1692   \n",
       "32                          582                    2649   \n",
       "33                          533                    1964   \n",
       "34                          430                    1885   \n",
       "35                          617                    1667   \n",
       "36                          626                    1364   \n",
       "37                          499                    1760   \n",
       "38                          670                    1759   \n",
       "39                          745                    1496   \n",
       "40                          877                    1353   \n",
       "41                          313                    1074   \n",
       "42                          342                     952   \n",
       "43                          312                    1353   \n",
       "44                          393                    1553   \n",
       "\n",
       "    Miscellaneous offences   Total  Population  Crime_Index_Lagged  \n",
       "0                     9651  331751     3112900           10.657297  \n",
       "1                     9836  294409     3124900           10.657297  \n",
       "2                     7878  252119     3156100            9.421389  \n",
       "3                     7774  254658     3199300            7.988308  \n",
       "4                     8552  274022     3227100            7.959804  \n",
       "5                     7561  272657     3247100            8.491277  \n",
       "6                     7553  298086     3246300            8.396939  \n",
       "7                     6921  292500     3274400            9.182331  \n",
       "8                     7362  308817     3283400            8.932934  \n",
       "9                     7561  270585     3299200            9.405403  \n",
       "10                    8153  241026     3329800            8.201534  \n",
       "11                    9192  255878     3495100            7.238453  \n",
       "12                   11027  258491     3531700            7.321049  \n",
       "13                   10760  261371     3572200            7.319166  \n",
       "14                   10835  271906     3620000            7.316808  \n",
       "15                   11028  276802     3673400            7.511215  \n",
       "16                    6823  269061     3732000            7.535308  \n",
       "17                    3860  266665     3781300            7.209566  \n",
       "18                    3989  272436     3815000            7.052204  \n",
       "19                    2547  262059     3835100            7.141180  \n",
       "20                    2184  266422     3857700            6.833173  \n",
       "21                    2609  255739     3880500            6.906239  \n",
       "22                    4545  265322     3948500            6.590362  \n",
       "23                    2834  282515     4027200            6.719564  \n",
       "24                    2814  287754     4087500            7.015172  \n",
       "25                    3107  297185     4133900            7.039853  \n",
       "26                    4216  314727     4184600            7.188974  \n",
       "27                    2418  333004     4223800            7.521077  \n",
       "28                    1826  348638     4259800            7.883991  \n",
       "29                    1679  346707     4302600            8.184375  \n",
       "30                    1551  308540     4350700            8.058081  \n",
       "31                    1382  284899     4384000            7.091732  \n",
       "32                    1410  272250     4408100            6.498609  \n",
       "33                    1038  229410     4442100            6.176130  \n",
       "34                     864  218170     4516500            5.164449  \n",
       "35                     862  220185     4609400            4.830510  \n",
       "36                     731  225931     4714100            4.776869  \n",
       "37                     666  221757     4813600            4.792665  \n",
       "38                     839  212872     4900600            4.606885  \n",
       "39                     782  204566     4979200            4.343795  \n",
       "40                     784  212064     5090200            4.108411  \n",
       "41                     531  168188     5111300            4.166123  \n",
       "42                     657  192313     5117200            3.290513  \n",
       "43                     660  216533     5223100            3.758169  \n",
       "44                     591  226317     5269939            4.145680  \n",
       "\n",
       "[45 rows x 21 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f38bc1-81f1-45cb-8e3e-78337841dffb",
   "metadata": {},
   "source": [
    "# train a lasso with alpha 0.001 and max iter 1000 and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8815fbb0-a483-4c30-a073-94f416616e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e-02, tolerance: 1.320e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Lasso</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.001)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.001)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize model\n",
    "lasso = Lasso(alpha=0.001, max_iter=1000)\n",
    "\n",
    "# Train model\n",
    "lasso.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "941d559e-1167-4c03-bf56-ccb87712e1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lasso_alpha_0_001_maxiter_1000.pkl']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(lasso, \"lasso_alpha_0_001_maxiter_1000.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d80c9476-3b6b-4048-bd41-8db66d83703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e-02, tolerance: 1.320e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lasso_alpha_0_001_maxiter_1000.joblib']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import joblib\n",
    "\n",
    "# Train Lasso model\n",
    "lasso = Lasso(alpha=0.001, max_iter=1000)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Save as .joblib file\n",
    "joblib.dump(lasso, \"lasso_alpha_0_001_maxiter_1000.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976d842-ba62-4641-b0a8-13ff4420c0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d02ba-a84d-4233-a133-044e0b850833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c859b5b-71e1-4858-b849-66adf2ab7a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702451b-c0bc-427c-8909-c372ba504e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c6cf5-2861-490c-848a-82a4400767af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68bc86-abc7-4a60-8ce6-07c9d5bdf16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f02df3-49e5-4706-bd07-f8b3c5500716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093aefe-e921-411e-b23b-1bd994360f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2c099-ac55-48ac-a3e4-42c34041fd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2bdd7-7860-4ca1-8ffa-3fe26f582339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fbed3-8ad8-473c-a028-4c1cf98dcc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1bafb-f149-461d-97d3-7a0316936421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1e085-297b-47aa-a0c1-5cc35f6bf57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675f9f2-4fcf-4ede-8a51-02122c60b8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760fabb-9b89-4565-b019-f60471c1612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aababf-2417-421d-84d0-41d7ba7aab58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b8b6c-8e6d-4598-ac47-22e2aaf43993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379ffd3-d231-4172-ab69-9d0ff1e8adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b900a8-61d3-4f06-a46a-8ff2eb84bfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
